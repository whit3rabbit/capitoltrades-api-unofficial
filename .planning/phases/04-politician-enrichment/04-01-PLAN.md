---
phase: 04-politician-enrichment
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - capitoltraders_lib/src/scrape.rs
  - capitoltraders_lib/src/db.rs
  - capitoltraders_lib/src/lib.rs
  - capitoltraders_lib/tests/fixtures/politicians_committee_filtered.html
autonomous: true

must_haves:
  truths:
    - "ScrapeClient can fetch politician listings filtered by committee code"
    - "DB can replace all politician_committees rows atomically"
    - "DB can mark all politicians with committee data as enriched"
  artifacts:
    - path: "capitoltraders_lib/src/scrape.rs"
      provides: "politicians_by_committee(code, page) method on ScrapeClient"
      contains: "pub async fn politicians_by_committee"
    - path: "capitoltraders_lib/src/db.rs"
      provides: "replace_all_politician_committees(), mark_politicians_enriched() methods"
      contains: "pub fn replace_all_politician_committees"
    - path: "capitoltraders_lib/tests/fixtures/politicians_committee_filtered.html"
      provides: "Fixture for committee-filtered politician listing page (from live data or synthetic)"
  key_links:
    - from: "scrape.rs::politicians_by_committee"
      to: "scrape.rs::parse_politician_cards"
      via: "reuses existing card parser"
      pattern: "parse_politician_cards"
    - from: "db.rs::replace_all_politician_committees"
      to: "schema/sqlite.sql politician_committees table"
      via: "INSERT OR IGNORE with EXISTS subquery"
      pattern: "politician_committees"
---

<objective>
Add committee membership scraping and DB persistence for Phase 4 politician enrichment.

Purpose: The politician detail page RSC payload does NOT contain committee data (confirmed by research). Instead, the politician listing page supports server-side committee filtering (/politicians?committee={code}). This plan adds a ScrapeClient method to fetch committee-filtered listing pages, plus DB methods to persist and manage the resulting politician-to-committee mappings.

Output: ScrapeClient::politicians_by_committee(), Db::replace_all_politician_committees(), Db::mark_politicians_enriched(), fixture, and tests.
</objective>

<execution_context>
@/Users/whit3rabbit/.claude/get-shit-done/workflows/execute-plan.md
@/Users/whit3rabbit/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-politician-enrichment/04-RESEARCH.md
@capitoltraders_lib/src/scrape.rs
@capitoltraders_lib/src/db.rs
@capitoltraders_lib/src/lib.rs
@capitoltraders_lib/src/validation.rs
@schema/sqlite.sql
</context>

<tasks>

<task type="auto">
  <name>Task 1: Verify parse_politician_cards against live committee-filtered page, then add scraper method and fixture</name>
  <files>
    capitoltraders_lib/src/scrape.rs
    capitoltraders_lib/tests/fixtures/politicians_committee_filtered.html
  </files>
  <action>
**Step 0: Live verification of parse_politician_cards on committee-filtered pages (MANDATORY FIRST)**

Before creating any fixture or writing any code, verify that the existing parse_politician_cards regex works on committee-filtered listing pages. Research Open Question 4 flagged this as uncertain.

a) Write a small temporary Rust test (or ad-hoc main function) that:
   - Creates a ScrapeClient
   - Fetches https://www.capitoltrades.com/politicians?committee=ssfi (Senate Finance, known small committee)
   - Calls extract_rsc_payload on the HTML
   - Calls parse_politician_cards on the payload
   - Prints the number of cards parsed and the politician_ids

b) Run the test. Two outcomes:

   **If parse_politician_cards succeeds (expected):**
   - Save the fetched HTML as the fixture at `capitoltraders_lib/tests/fixtures/politicians_committee_filtered.html` (real data is better than synthetic).
   - Alternatively, if the real page is too large, create a synthetic fixture modeled on the real page's structure. But prefer real data.
   - Proceed to Step 1 below.

   **If parse_politician_cards fails:**
   - Examine the committee-filtered page's RSC payload structure vs the unfiltered page.
   - Identify the regex mismatch (e.g., different CSS class names, different field ordering).
   - Option A: Fix parse_politician_cards to handle both formats (preferred if the diff is small).
   - Option B: Create a simplified parser `parse_politician_ids_from_cards` that only extracts politician_ids (sufficient for committee mapping -- we only need the ID, not name/party/stats).
   - Document what changed and why in a code comment.
   - Then proceed to Step 1 with the working parser.

c) Remove the temporary test code after verification.

**Step 1: Create the fixture file**

Place the fixture at `capitoltraders_lib/tests/fixtures/politicians_committee_filtered.html`. If using real fetched data (preferred), save the HTML directly. If synthetic, follow the same RSC payload structure used in the existing politician listing page (self.__next_f.push format). Include 3+ politician cards with distinct politician_ids, names, parties, states, trade/issuer counts, volume, and last_traded dates. Include a totalCount field. This fixture models the response from /politicians?committee=ssfi (Senate Finance).

**Step 2: Add politicians_by_committee() method to ScrapeClient in scrape.rs:**

```rust
pub async fn politicians_by_committee(
    &self,
    committee_code: &str,
    page: i64,
) -> Result<ScrapePage<ScrapedPoliticianCard>, ScrapeError>
```
- URL format: `{base_url}/politicians?committee={committee_code}&page={page}`
- Reuse `extract_rsc_payload()`, `extract_number()` for totalCount, and `parse_politician_cards()` -- identical to existing `politicians_page()` except the URL includes the committee query parameter.
- Compute total_pages the same way politicians_page does.

**Step 3: Add a test in the scrape.rs test module:**

- `test_politicians_by_committee_fixture`: Load the fixture via include_str!, call extract_rsc_payload, then parse_politician_cards. Assert that the expected number of cards are returned with valid politician_ids and that parsing succeeds without error.

Note: The fixture format must match what parse_politician_cards expects. The regex pattern looks for: `href":"/politicians/{id}"`, `cell--name`, `party--{party}`, `us-state-full--{state}`, `cell--count-trades`, `cell--count-issuers`, `cell--volume`, `cell--last-traded`. If using real data, this is automatically satisfied. If synthetic, study the existing politician card regex carefully.
  </action>
  <verify>
    `cargo test -p capitoltraders_lib test_politicians_by_committee_fixture` passes.
    `cargo clippy -p capitoltraders_lib` produces no warnings.
  </verify>
  <done>
    parse_politician_cards has been verified against a live committee-filtered page. politicians_by_committee() method exists on ScrapeClient, reusing the (possibly adjusted) parser. Fixture-based test confirms parsing works for committee-filtered pages. If the regex needed changes, those changes are documented in code comments.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add DB committee persistence and enrichment tracking methods with tests</name>
  <files>
    capitoltraders_lib/src/db.rs
    capitoltraders_lib/src/lib.rs
  </files>
  <action>
1. Add `replace_all_politician_committees()` method to Db in db.rs:
   ```rust
   pub fn replace_all_politician_committees(
       &self,
       memberships: &[(String, String)],  // (politician_id, committee_code)
   ) -> Result<usize, DbError>
   ```
   - Use `unchecked_transaction()` (following the Phase 2 pattern for &self receiver).
   - DELETE all rows from politician_committees within the transaction.
   - INSERT OR IGNORE each (politician_id, committee_code) pair, with an EXISTS subquery to skip politician_ids not in the politicians table (handles the "politicians with no trades" case from research Pitfall 6).
   - Return the number of rows actually inserted.

2. Add `mark_politicians_enriched()` method to Db:
   ```rust
   pub fn mark_politicians_enriched(&self) -> Result<(), DbError>
   ```
   - UPDATE politicians SET enriched_at = datetime('now') WHERE enriched_at IS NULL
   - This marks all politicians as enriched after committee data is populated.

3. Add `count_unenriched_politicians()` method to Db (parallel to count_unenriched_trades):
   ```rust
   pub fn count_unenriched_politicians(&self) -> Result<i64, DbError>
   ```
   - SELECT COUNT(*) FROM politicians WHERE enriched_at IS NULL

4. Re-export from lib.rs: No new types need re-exporting (methods are on existing Db struct).

5. Add tests in the db.rs test module (5-6 tests):
   - `test_replace_all_politician_committees_basic`: Insert 2 politicians, call replace_all with 3 memberships (2 for known politicians, 1 for unknown), verify 2 rows inserted, unknown skipped.
   - `test_replace_all_politician_committees_replaces`: Call replace_all twice with different data, verify second call replaces first (old data gone, new data present).
   - `test_replace_all_politician_committees_empty`: Call with empty slice, verify table is cleared.
   - `test_mark_politicians_enriched`: Insert politician with NULL enriched_at, call mark_politicians_enriched, verify enriched_at is now set.
   - `test_count_unenriched_politicians`: Insert 2 politicians, verify count is 2, mark one enriched, verify count is 1.
  </action>
  <verify>
    `cargo test -p capitoltraders_lib replace_all_politician_committees` passes.
    `cargo test -p capitoltraders_lib mark_politicians_enriched` passes.
    `cargo test -p capitoltraders_lib count_unenriched_politicians` passes.
    `cargo clippy -p capitoltraders_lib` produces no warnings.
  </verify>
  <done>
    Db has replace_all_politician_committees (atomic clear+rebuild with FK safety), mark_politicians_enriched (timestamp update), and count_unenriched_politicians (queue counting). All 5+ tests pass.
  </done>
</task>

</tasks>

<verification>
- `cargo test --workspace` -- all existing tests still pass, new tests pass
- `cargo clippy --workspace` -- no warnings
- politicians_by_committee method exists and is callable with a committee code and page number
- replace_all_politician_committees handles the FK safety case (unknown politicians silently skipped)
- mark_politicians_enriched sets enriched_at on all NULL rows
</verification>

<success_criteria>
- parse_politician_cards verified against a real committee-filtered page before fixture creation
- ScrapeClient::politicians_by_committee(code, page) fetches committee-filtered listing pages and reuses parse_politician_cards
- Db::replace_all_politician_committees() atomically clears and rebuilds the politician_committees table from a Vec of (politician_id, committee_code) pairs
- Db::mark_politicians_enriched() sets enriched_at timestamp on all politicians
- Db::count_unenriched_politicians() returns count of politicians without enrichment
- Fixture reflects actual committee-filtered page structure (real or verified-synthetic)
- All new tests pass, no regressions
</success_criteria>

<output>
After completion, create `.planning/phases/04-politician-enrichment/04-01-SUMMARY.md`
</output>
