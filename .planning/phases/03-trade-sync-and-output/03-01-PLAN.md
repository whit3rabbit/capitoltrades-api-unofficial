---
phase: 03-trade-sync-and-output
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - capitoltraders_lib/src/db.rs
  - capitoltraders_lib/src/lib.rs
  - capitoltraders_cli/src/commands/sync.rs
autonomous: true

must_haves:
  truths:
    - "sync --enrich runs a post-ingest enrichment loop that calls trade_detail() for each unenriched trade and persists results via update_trade_detail()"
    - "sync --enrich --dry-run reports the count of unenriched trades without making any HTTP requests"
    - "sync --enrich --batch-size N limits enrichment to N trades per run"
    - "Re-running sync --enrich skips trades that already have enriched_at set"
    - "Interrupting enrichment mid-run and restarting picks up from where it left off"
    - "Default detail page delay is 500ms, configurable via --detail-delay-ms"
    - "--with-trade-details is deprecated (hidden alias for --enrich)"
  artifacts:
    - path: "capitoltraders_lib/src/db.rs"
      provides: "count_unenriched_trades() method"
      contains: "fn count_unenriched_trades"
    - path: "capitoltraders_cli/src/commands/sync.rs"
      provides: "enrich_trades() async function, --enrich/--dry-run/--batch-size flags on SyncArgs"
      contains: "async fn enrich_trades"
  key_links:
    - from: "capitoltraders_cli/src/commands/sync.rs"
      to: "capitoltraders_lib/src/db.rs"
      via: "db.get_unenriched_trade_ids() and db.update_trade_detail()"
      pattern: "get_unenriched_trade_ids|update_trade_detail"
    - from: "capitoltraders_cli/src/commands/sync.rs"
      to: "capitoltraders_lib/src/scrape.rs"
      via: "scraper.trade_detail(tx_id)"
      pattern: "trade_detail"
---

<objective>
Wire the trade enrichment pipeline into the sync command with post-ingest enrichment, smart-skip, dry-run mode, and configurable throttle delay.

Purpose: Phase 2 built the extraction (trade_detail) and persistence (update_trade_detail) layers. This plan connects them into a usable sync workflow so users can enrich their trade database with a single command.

Output: Working `sync --enrich` command that fetches trade detail pages, persists enrichment, supports dry-run and batch-size, and deprecates the old --with-trade-details flag.
</objective>

<execution_context>
@/Users/whit3rabbit/.claude/get-shit-done/workflows/execute-plan.md
@/Users/whit3rabbit/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-trade-sync-and-output/03-RESEARCH.md
@.planning/phases/02-trade-extraction/02-02-SUMMARY.md
@capitoltraders_cli/src/commands/sync.rs
@capitoltraders_lib/src/db.rs
@capitoltraders_lib/src/lib.rs
@capitoltraders_lib/src/scrape.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add count_unenriched_trades and enrich_trades pipeline</name>
  <files>capitoltraders_lib/src/db.rs, capitoltraders_lib/src/lib.rs, capitoltraders_cli/src/commands/sync.rs</files>
  <action>
1. In db.rs, add a `count_unenriched_trades(&self) -> Result<i64, DbError>` method that runs `SELECT COUNT(*) FROM trades WHERE enriched_at IS NULL`. Place it near the existing `get_unenriched_trade_ids` method.

2. In lib.rs, add `ScrapedTradeDetail` to the re-exports from `scrape` module (it is needed by sync.rs to pass to update_trade_detail). The current re-export line is:
   `pub use scrape::{ScrapeClient, ScrapeError, ScrapePage, ScrapedIssuerDetail, ScrapedIssuerList, ScrapedPoliticianCard, ScrapedTrade};`
   Add `ScrapedTradeDetail` to this list.

3. In sync.rs, modify `SyncArgs` to add these new fields:
   - `--enrich` (bool, long) -- "Enrich trade details after sync (fetches individual trade pages)"
   - `--dry-run` (bool, long, requires = "enrich") -- "Show how many trades would be enriched without fetching"
   - `--batch-size` (Option<i64>, long) -- "Maximum trades to enrich per run (default: all)"
   - Change `--details-delay-ms` default from "250" to "500" (PERF-04)
   - Mark `--with-trade-details` as hidden: add `#[arg(long, hide = true)]` to make it a hidden alias

4. In sync.rs, add an `EnrichmentResult` struct:
   ```rust
   struct EnrichmentResult {
       enriched: usize,
       skipped: usize,
       failed: usize,
       total: usize,
   }
   ```

5. In sync.rs, add an `async fn enrich_trades(scraper: &ScrapeClient, db: &Db, batch_size: Option<i64>, detail_delay_ms: u64, dry_run: bool) -> Result<EnrichmentResult>` function:
   - Call `db.get_unenriched_trade_ids(batch_size)` to get the queue
   - If dry_run: call `db.count_unenriched_trades()` for total count, print "{total} trades would be enriched ({batch_size} selected)" to stderr, return early with enriched=0
   - If queue is empty: print "No trades need enrichment" to stderr, return early
   - Print "Enriching {len} trades..." to stderr
   - Loop over trade_ids: call `scraper.trade_detail(tx_id).await`, on Ok call `db.update_trade_detail(tx_id, &detail)?` and increment enriched, on Err print warning to stderr and increment failed
   - After each trade, sleep for detail_delay_ms (if > 0) using `tokio::time::sleep`
   - Every 50 trades (and at end), print progress to stderr: "  Progress: {i+1}/{total} ({enriched} enriched, {failed} failed)"
   - Return EnrichmentResult

6. In sync.rs `run()` function, after the existing `sync_trades` call and meta update, add:
   ```rust
   // Treat --with-trade-details as alias for --enrich
   let should_enrich = args.enrich || args.with_trade_details;
   if should_enrich {
       let result = enrich_trades(&scraper, &db, args.batch_size, args.details_delay_ms, args.dry_run).await?;
       eprintln!("Enrichment: {}/{} trades processed ({} failed)", result.enriched, result.total, result.failed);
   }
   ```
   Note: The enrichment function takes `&Db` (not `&mut Db`) because `update_trade_detail` uses `unchecked_transaction` which only needs `&self`.

   Important: The existing inline detail fetch in sync_trades (lines 156-171) should remain unchanged for now. When --with-trade-details is used, it will trigger BOTH the inline fetch (filing_url/filing_id only) AND the post-ingest enrichment. The post-ingest enrichment is the one that matters -- it captures all fields. The inline fetch is harmless but redundant. Do not remove it to avoid breaking anything.

7. Add unit tests in db.rs for count_unenriched_trades:
   - Test with 0 unenriched trades (all have enriched_at)
   - Test with some unenriched trades (returns correct count)
   - Test with all unenriched trades
  </action>
  <verify>
Run `cargo check --workspace` to verify compilation. Run `cargo test --workspace count_unenriched` to verify the new DB tests pass. Run `cargo clippy --workspace` for lint.
  </verify>
  <done>
sync.rs has --enrich, --dry-run, --batch-size flags. enrich_trades() function exists and compiles. count_unenriched_trades() has 3 passing tests. --with-trade-details is hidden but still functional as an alias. Default detail delay is 500ms.
  </done>
</task>

<task type="auto">
  <name>Task 2: Integration test for enrichment pipeline</name>
  <files>capitoltraders_cli/src/commands/sync.rs</files>
  <action>
Add a test module at the bottom of sync.rs (or in a separate test file if the module already has tests) to verify the enrichment pipeline logic.

Since the enrichment pipeline requires both a ScrapeClient (HTTP) and a Db (SQLite), and we cannot easily construct a wiremock-based test for the full flow in unit tests, add the following targeted tests:

1. Test that `enrich_trades` with an empty unenriched queue returns immediately:
   - Create an in-memory Db, init schema
   - Call `db.count_unenriched_trades()` -- assert 0
   - Call `db.get_unenriched_trade_ids(None)` -- assert empty vec

2. Test the enrichment queue ordering after partial enrichment:
   - Create in-memory Db, init
   - Insert 3 trades via upsert_scraped_trades (use minimal ScrapedTrade structs with tx_ids 100, 200, 300)
   - Call get_unenriched_trade_ids(None) -- assert [100, 200, 300]
   - Call update_trade_detail(100, &ScrapedTradeDetail::default()) to mark trade 100 as enriched
   - Call get_unenriched_trade_ids(None) -- assert [200, 300] (100 is skipped)
   - Call count_unenriched_trades() -- assert 2

3. Test batch_size limiting:
   - Same setup as above with 3 unenriched trades
   - Call get_unenriched_trade_ids(Some(2)) -- assert returns exactly 2 IDs
   - Call count_unenriched_trades() -- assert still 3 (count is independent of limit)

These tests verify the smart-skip (TRADE-09) and batch checkpointing (TRADE-10) at the database level. The HTTP enrichment loop is straightforward async code that delegates to these methods.

Note: To construct minimal ScrapedTrade structs for insertion, you will need to create structs with all required fields populated. Look at the existing test patterns in db.rs (search for `ScrapedTrade` in test modules) for the exact field structure. Import ScrapedTrade and any nested types from capitoltraders_lib::scrape.
  </action>
  <verify>
Run `cargo test --workspace enrichment_queue` and `cargo test --workspace batch_size` (or whatever the test names end up being) to confirm all pass. Run `cargo test --workspace` to confirm no regressions.
  </verify>
  <done>
3 integration tests verify: (1) empty queue returns immediately, (2) partial enrichment removes enriched trades from queue, (3) batch_size limits the queue. All workspace tests pass.
  </done>
</task>

</tasks>

<verification>
- `cargo check --workspace` compiles without errors
- `cargo test --workspace` all tests pass (existing 235 + new tests)
- `cargo clippy --workspace` no new warnings
- `capitoltraders sync --help` shows --enrich, --dry-run, --batch-size flags
- `capitoltraders sync --help` shows --detail-delay-ms default of 500
- `capitoltraders sync --help` does NOT show --with-trade-details (hidden)
</verification>

<success_criteria>
- sync command accepts --enrich, --dry-run, --batch-size flags
- --with-trade-details is hidden but functional as --enrich alias
- Default detail delay is 500ms (PERF-04)
- count_unenriched_trades() returns correct count
- Enrichment queue respects enriched_at (smart-skip TRADE-09)
- Enrichment queue respects batch_size limit
- Per-trade commit provides crash-safe checkpointing (TRADE-10, inherited from Phase 2)
</success_criteria>

<output>
After completion, create `.planning/phases/03-trade-sync-and-output/03-01-SUMMARY.md`
</output>
