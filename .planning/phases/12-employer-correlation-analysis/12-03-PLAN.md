---
phase: 12-employer-correlation-analysis
plan: 03
type: execute
wave: 2
depends_on: ["12-01", "12-02"]
files_modified:
  - capitoltraders_cli/src/commands/map_employers.rs
  - capitoltraders_cli/src/commands/mod.rs
  - capitoltraders_cli/src/main.rs
autonomous: true

must_haves:
  truths:
    - "User can export unmatched employers to CSV with fuzzy match suggestions"
    - "User can import confirmed mappings from an edited CSV"
    - "Export CSV includes employer, suggestion columns, and a confirmed_issuer_ticker column for user to fill"
    - "Import validates that confirmed tickers exist in the issuers table before persisting"
    - "Seed data can be loaded into the database via a load-seed subcommand"
    - "CSV export uses formula injection sanitization on employer names"
  artifacts:
    - path: "capitoltraders_cli/src/commands/map_employers.rs"
      provides: "map-employers CLI command with export, import, and load-seed subcommands"
      contains: "MapEmployersArgs"
    - path: "capitoltraders_cli/src/main.rs"
      provides: "MapEmployers variant in Commands enum"
      contains: "MapEmployers"
  key_links:
    - from: "capitoltraders_cli/src/commands/map_employers.rs"
      to: "capitoltraders_lib::employer_mapping"
      via: "normalize_employer, match_employer, load_seed_data, is_blacklisted"
      pattern: "employer_mapping"
    - from: "capitoltraders_cli/src/commands/map_employers.rs"
      to: "capitoltraders_lib::Db"
      via: "upsert_employer_mappings, get_unmatched_employers, get_all_issuers_for_matching, insert_employer_lookups, issuer_exists_by_ticker"
      pattern: "db\\."
---

<objective>
Create the map-employers CLI command with export/import/load-seed subcommands for building the employer-to-issuer mapping database.

Purpose: This is the primary workflow for building employer-to-issuer correlations. Users export unmatched employers, review suggestions in a spreadsheet, and import confirmed mappings. The load-seed subcommand bootstraps the database with curated mappings from the TOML seed file.

Output: map-employers CLI command with 3 subcommands, registered in main.rs.
</objective>

<execution_context>
@/Users/whit3rabbit/.claude/get-shit-done/workflows/execute-plan.md
@/Users/whit3rabbit/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/12-employer-correlation-analysis/12-RESEARCH.md
@.planning/phases/12-employer-correlation-analysis/12-01-SUMMARY.md
@.planning/phases/12-employer-correlation-analysis/12-02-SUMMARY.md
@capitoltraders_cli/src/main.rs
@capitoltraders_cli/src/commands/mod.rs
@capitoltraders_cli/src/commands/donations.rs (for pattern reference: CLI structure, DB opening, filter validation)
@capitoltraders_lib/src/employer_mapping.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create map-employers CLI command with export and import subcommands</name>
  <files>
    capitoltraders_cli/src/commands/map_employers.rs
    capitoltraders_cli/src/commands/mod.rs
    capitoltraders_cli/src/main.rs
  </files>
  <action>
    1. Create `capitoltraders_cli/src/commands/map_employers.rs`:

    Use clap's subcommand pattern (similar to how sync has separate concerns):

    ```rust
    #[derive(Args)]
    pub struct MapEmployersArgs {
        /// SQLite database path (required)
        #[arg(long)]
        pub db: PathBuf,

        #[command(subcommand)]
        pub action: MapEmployersAction,
    }

    #[derive(Subcommand)]
    pub enum MapEmployersAction {
        /// Export unmatched employers with fuzzy match suggestions to CSV
        Export(ExportArgs),
        /// Import confirmed employer-to-issuer mappings from CSV
        Import(ImportArgs),
        /// Load seed data (curated employer mappings) into database
        LoadSeed(LoadSeedArgs),
    }

    #[derive(Args)]
    pub struct ExportArgs {
        /// Output CSV file path
        #[arg(long, short = 'o')]
        pub output: PathBuf,

        /// Jaro-Winkler fuzzy match threshold (0.0-1.0)
        #[arg(long, default_value = "0.85")]
        pub threshold: f64,

        /// Maximum number of unmatched employers to export
        #[arg(long)]
        pub limit: Option<i64>,
    }

    #[derive(Args)]
    pub struct ImportArgs {
        /// Input CSV file path with confirmed mappings
        #[arg(long, short = 'i')]
        pub input: PathBuf,
    }

    #[derive(Args)]
    pub struct LoadSeedArgs {
        /// Dry run: show what would be loaded without writing to DB
        #[arg(long)]
        pub dry_run: bool,
    }
    ```

    2. Implement `pub fn run(args: &MapEmployersArgs) -> Result<()>`:
    - Open DB, call init()
    - Match on args.action:
      - Export -> run_export()
      - Import -> run_import()
      - LoadSeed -> run_load_seed()

    3. Implement `fn run_export(db: &Db, args: &ExportArgs) -> Result<()>`:
    - Validate threshold is between 0.0 and 1.0
    - Call db.get_unmatched_employers(args.limit) to get raw employer names
    - Call db.get_all_issuers_for_matching() to get issuers
    - For each unmatched employer:
      - Skip if is_blacklisted()
      - Normalize with normalize_employer()
      - Call match_employer() against issuers (but use args.threshold instead of hardcoded 0.85 -- need to either pass threshold to match_employer or do matching inline). Since match_employer uses 0.85 hardcoded, do matching inline here: normalize, check exact match, then if len >= 5 call jaro_winkler directly with the custom threshold.
      - Actually, better approach: Add a `match_employer_with_threshold` function or make the threshold a parameter of match_employer. Update Plan 01's match_employer to accept threshold as parameter: `pub fn match_employer(employer: &str, issuers: &[(i64, String, String)], threshold: f64) -> Option<MatchResult>`. If Plan 01 already used 0.85 hardcoded, update it here (the executor should modify employer_mapping.rs to accept threshold).
    - Write CSV with columns: employer, normalized, suggestion_ticker, suggestion_name, suggestion_sector, confidence, confirmed_ticker, notes
    - Use csv::Writer with sanitize_csv_field on employer names (import sanitize from output module or reimplement -- check if it is in output.rs or a shared location)
    - The sanitize_csv_field function exists in the CLI output module. Import it: `use crate::output::sanitize_csv_field;`. If it is not public, make it pub.
    - Print summary: "Exported N unmatched employers to {path}. M had suggestions above threshold {t}."

    4. Implement `fn run_import(db: &Db, args: &ImportArgs) -> Result<()>`:
    - Read CSV from args.input using csv::Reader
    - For each row:
      - Read confirmed_ticker column. If empty or missing, skip (user did not confirm this row).
      - Validate issuer exists: db.issuer_exists_by_ticker(&confirmed_ticker)?
      - If not exists, print warning and skip
      - Collect: (normalized_employer, confirmed_ticker, 1.0 confidence, "manual" match_type)
      - Also collect employer_lookup entry: (raw_employer_lower, normalized_employer)
    - Call db.upsert_employer_mappings() with collected mappings
    - Call db.insert_employer_lookups() with collected lookups
    - Print summary: "Imported N confirmed employer mappings. Skipped M (no confirmed ticker or invalid ticker)."

    5. Implement `fn run_load_seed(db: &Db, args: &LoadSeedArgs) -> Result<()>`:
    - Call load_seed_data() from employer_mapping module
    - For each SeedMapping:
      - For each employer_name variant:
        - Normalize the variant
        - Check db.issuer_exists_by_ticker(&seed.issuer_ticker) -- if ticker not in DB, warn and skip (user may not have synced that issuer)
        - Collect: (normalized_employer, issuer_ticker, seed.confidence, "exact" match_type)
        - Collect employer_lookup: (employer_name_variant.to_lowercase().trim(), normalized_employer)
    - If dry_run, just print what would be loaded and return
    - Otherwise call db.upsert_employer_mappings() and db.insert_employer_lookups()
    - Print: "Loaded N seed mappings for M issuers. Skipped K (ticker not in database)."

    6. Add `pub mod map_employers;` to commands/mod.rs.

    7. Register in main.rs:
    - Add `MapEmployers(commands::map_employers::MapEmployersArgs)` to Commands enum
    - Add match arm: `Commands::MapEmployers(args) => commands::map_employers::run(args)?`
    - This command does NOT require an OpenFEC API key (no API calls)
  </action>
  <verify>
    `cargo check --workspace` -- compiles.
    `cargo clippy --workspace` -- no warnings.
    `cargo run -p capitoltraders_cli -- map-employers --help` -- shows export/import/load-seed subcommands.
    `cargo run -p capitoltraders_cli -- map-employers export --help` -- shows --output, --threshold, --limit flags.
  </verify>
  <done>
    map-employers command registered with 3 subcommands. Export generates CSV with suggestions. Import reads confirmed CSV. Load-seed bootstraps from TOML. All compile and pass clippy.
  </done>
</task>

<task type="auto">
  <name>Task 2: Update match_employer to accept threshold parameter and verify end-to-end export flow</name>
  <files>
    capitoltraders_lib/src/employer_mapping.rs
    capitoltraders_cli/src/commands/map_employers.rs
  </files>
  <action>
    1. Update `match_employer` in employer_mapping.rs to accept a threshold parameter:
    `pub fn match_employer(employer: &str, issuers: &[(i64, String, String)], threshold: f64) -> Option<MatchResult>`
    - Replace hardcoded 0.85 with the threshold parameter
    - Update all existing tests that call match_employer to pass 0.85 as the threshold

    2. Verify the export flow works correctly by ensuring the CSV writer:
    - Uses serde::Serialize derive on an ExportRow struct for clean CSV output
    - Sanitizes employer names against CSV formula injection
    - Handles the case where get_unmatched_employers returns empty vec (no donations synced yet) with a helpful message: "No unmatched employers found. Run 'capitoltraders sync-donations' first to populate donation data."
    - Handles the case where get_all_issuers_for_matching returns empty vec (no issuers synced) with message: "No issuers in database. Run 'capitoltraders sync' first."

    3. Make sure sanitize_csv_field in the CLI output module is pub (or pub(crate) at minimum) so map_employers.rs can import it. Check current visibility and update if needed.
  </action>
  <verify>
    `cargo test -p capitoltraders_lib employer_mapping` -- all tests pass (with updated threshold parameter).
    `cargo check --workspace` -- compiles.
    `cargo clippy --workspace` -- no warnings.
  </verify>
  <done>
    match_employer accepts configurable threshold. Export flow handles empty states gracefully. CSV sanitization applied to employer names. All tests pass.
  </done>
</task>

</tasks>

<verification>
- `cargo test --workspace` -- all tests pass
- `cargo clippy --workspace` -- no warnings
- `cargo run -p capitoltraders_cli -- map-employers --help` shows 3 subcommands
- map-employers export writes valid CSV with headers and sanitized fields
- map-employers import validates ticker existence before persisting
- map-employers load-seed respects --dry-run flag
</verification>

<success_criteria>
- map-employers command registered in CLI with export, import, load-seed subcommands
- Export writes CSV: employer, normalized, suggestion columns, confirmed_ticker (empty for user), notes
- Import reads CSV, validates confirmed_ticker against issuers table, persists manual mappings
- Load-seed bootstraps database from TOML seed data
- match_employer accepts configurable threshold
- Empty state handling with helpful messages
</success_criteria>

<output>
After completion, create `.planning/phases/12-employer-correlation-analysis/12-03-SUMMARY.md`
</output>
