---
phase: 02-trade-extraction
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - capitoltraders_lib/src/scrape.rs
  - capitoltraders_lib/tests/fixtures/trade_detail_stock.html
  - capitoltraders_lib/tests/fixtures/trade_detail_option.html
  - capitoltraders_lib/tests/fixtures/trade_detail_minimal.html
autonomous: true

must_haves:
  truths:
    - "extract_trade_detail returns asset_type from fixture HTML"
    - "extract_trade_detail returns size, size_range_high, size_range_low from fixture HTML"
    - "extract_trade_detail returns price from fixture HTML where available"
    - "extract_trade_detail continues to return filing_url and filing_id (no regression)"
    - "extract_trade_detail returns has_capital_gains from fixture HTML"
    - "Committees and labels availability is documented from actual RSC payload inspection"
  artifacts:
    - path: "capitoltraders_lib/src/scrape.rs"
      provides: "Extended ScrapedTradeDetail struct and extract_trade_detail function"
      contains: "pub asset_type"
    - path: "capitoltraders_lib/tests/fixtures/trade_detail_stock.html"
      provides: "Real HTML fixture for stock trade detail page"
      min_lines: 10
  key_links:
    - from: "capitoltraders_lib/src/scrape.rs (extract_trade_detail)"
      to: "capitoltraders_lib/src/scrape.rs (extract_json_object)"
      via: "object extraction for full trade JSON"
      pattern: "extract_json_object"
---

<objective>
Capture real trade detail HTML fixtures and extend the trade detail scraper to extract all enrichable fields from RSC payloads.

Purpose: The existing extract_trade_detail() only extracts filing_url and filing_id. Listing pages leave asset_type as "unknown", size/size_range fields as NULL, and has_capital_gains as 0. The trade detail page RSC payload contains the full trade object, which this plan extracts.

Output: Extended ScrapedTradeDetail struct with all enrichable fields, updated extract_trade_detail() with full object extraction, HTML fixtures for regression tests, fixture-based unit tests, and documented findings on committees/labels availability (TRADE-05/TRADE-06).
</objective>

<execution_context>
@/Users/whit3rabbit/.claude/get-shit-done/workflows/execute-plan.md
@/Users/whit3rabbit/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-trade-extraction/02-RESEARCH.md
@capitoltraders_lib/src/scrape.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Capture trade detail HTML fixtures and document RSC payload structure</name>
  <files>
    capitoltraders_lib/tests/fixtures/trade_detail_stock.html
    capitoltraders_lib/tests/fixtures/trade_detail_option.html
    capitoltraders_lib/tests/fixtures/trade_detail_minimal.html
  </files>
  <action>
Create the tests/fixtures/ directory under capitoltraders_lib/.

Use curl to download 3 trade detail pages from capitoltrades.com. Pick trade IDs from different categories to get coverage:
1. A stock trade (look for a recent trade with a known stock ticker, e.g., try trade IDs in the 170000-175000 range)
2. A stock-option or other non-stock asset type trade (try different IDs until you find one)
3. A trade that may have minimal data (older trade, lower ID range like 1000-5000)

Use this curl pattern:
```
curl -s -o OUTPUT_PATH \
  -H 'accept: text/html,application/xhtml+xml' \
  -H 'user-agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36' \
  'https://www.capitoltrades.com/trades/TRADE_ID'
```

After downloading each fixture, verify it contains an RSC payload by checking for the "tradeId" needle:
```
grep -c "tradeId" FIXTURE_PATH
```
If a fixture does not contain "tradeId", the page returned a loading state. Try a different trade ID.

Once you have working fixtures, manually examine the RSC payload for each one. Write a temporary Rust program or use grep/search to answer these questions and document the findings as comments in the test file (Task 3):
1. Is the trade data in a single JSON object (like issuer_detail uses "issuerData":)?  What is the enclosing key?
2. What field names are used for: asset_type/assetType, size, sizeRangeHigh, sizeRangeLow, price, hasCapitalGains, filingUrl, filingId?
3. Are committees present anywhere in the payload? Search for committee-related strings.
4. Are labels present anywhere in the payload? Search for label-related strings (faang, crypto, memestock, spac, or "labels").
5. What is the approximate JSON object size around the tradeId match (to determine if the 500-char window is sufficient or needs to be replaced with object extraction)?

If the live site is unreachable or returns loading states for all attempts, create synthetic fixtures that mimic the expected RSC payload structure based on the existing extract_trade_detail code and the BFF API Trade struct. Mark them clearly as synthetic with a comment at the top.
  </action>
  <verify>
All 3 fixture files exist under capitoltraders_lib/tests/fixtures/ and each contains a "tradeId" string. Run: `grep -c "tradeId" capitoltraders_lib/tests/fixtures/trade_detail_*.html` -- each should return a non-zero count.
  </verify>
  <done>
3 HTML fixture files exist with real (or clearly-marked synthetic) RSC payload data. The RSC payload structure for trade detail pages is documented: field names, nesting, and whether committees/labels are present.
  </done>
</task>

<task type="auto">
  <name>Task 2: Extend ScrapedTradeDetail struct and extract_trade_detail() function</name>
  <files>capitoltraders_lib/src/scrape.rs</files>
  <action>
Extend the `ScrapedTradeDetail` struct (currently at line 78) with new fields:

```rust
#[derive(Debug, Default)]
pub struct ScrapedTradeDetail {
    // Existing
    pub filing_url: Option<String>,
    pub filing_id: Option<i64>,
    // TRADE-01: asset type
    pub asset_type: Option<String>,
    // TRADE-02: trade sizing
    pub size: Option<i64>,
    pub size_range_high: Option<i64>,
    pub size_range_low: Option<i64>,
    // TRADE-03: price
    pub price: Option<f64>,
    // Additional enrichment
    pub has_capital_gains: Option<bool>,
    // TRADE-05: committees (may be empty if not in payload)
    pub committees: Vec<String>,
    // TRADE-06: labels (may be empty if not in payload)
    pub labels: Vec<String>,
}
```

Rewrite `extract_trade_detail()` (currently at line 468) to use full JSON object extraction instead of the 500-char window approach. The implementation depends on what the fixtures reveal about the payload structure:

**If the trade data is in a single JSON object** (most likely, based on how issuer_detail works):
1. Find "tradeId":XXXXX in the payload
2. Walk backwards from the match position to find the opening `{` of the enclosing object
3. Use the existing `extract_json_object()` function to get the complete JSON object string
4. Parse it as `serde_json::Value`
5. Extract each field from the parsed object using `.get("fieldName")` chains
6. For asset_type: check both a direct `"assetType"` key and a nested `"asset"` object with `"assetType"` inside it
7. For filing_id: continue using `filing_id_from_url()` to derive it from the filing URL (existing pattern)
8. For committees: try `.get("committees")` and parse as `Vec<String>`. If not present, leave as empty vec.
9. For labels: try `.get("labels")` and parse as `Vec<String>`. If not present, leave as empty vec.

**If the data is scattered** (fallback):
- Increase the window from 500 to 2000 characters
- Use `extract_json_string` for string fields and direct parsing for numeric fields
- Use the existing `extract_number` helper for integer fields

Keep the existing fallback for filing_url extraction (the current window-based code) as a last resort if the object extraction approach fails for a given payload. This ensures backward compatibility.

Important:
- The function signature stays the same: `fn extract_trade_detail(payload: &str, trade_id: i64) -> ScrapedTradeDetail`
- The function must never panic -- return a default ScrapedTradeDetail if parsing fails
- Use actual field names discovered from the fixtures in Task 1 (the names above are from the BFF API and may differ in the RSC payload)
  </action>
  <verify>
`cargo check -p capitoltraders_lib` compiles without errors. `cargo clippy -p capitoltraders_lib` has no new warnings. The existing tests in the workspace still pass: `cargo test --workspace`.
  </verify>
  <done>
ScrapedTradeDetail has all enrichable fields. extract_trade_detail() uses full object extraction (or expanded window as fallback) to populate all fields from the RSC payload. All existing tests pass.
  </done>
</task>

<task type="auto">
  <name>Task 3: Add fixture-based unit tests for trade detail extraction</name>
  <files>capitoltraders_lib/src/scrape.rs</files>
  <action>
Add a new test submodule in scrape.rs (or extend the existing test module) with fixture-based tests. Use `include_str!` to load the HTML fixtures captured in Task 1.

Write these tests:

1. `test_extract_trade_detail_asset_type` -- Parse the stock fixture, verify asset_type is Some and not "unknown".

2. `test_extract_trade_detail_size_fields` -- Parse a fixture known to have size data, verify size is Some. Check size_range_high and size_range_low if present in the fixture.

3. `test_extract_trade_detail_filing_url_regression` -- Parse a fixture, verify filing_url and filing_id are extracted correctly (regression test for existing functionality).

4. `test_extract_trade_detail_price` -- Parse a fixture where price is expected, verify it is Some and a reasonable f64 value.

5. `test_extract_trade_detail_has_capital_gains` -- Parse a fixture, verify has_capital_gains is populated.

6. `test_extract_trade_detail_committees_availability` -- Parse all fixtures, document whether committees were found. Use `eprintln!` to output the finding. Assert the vec length matches what was found during fixture analysis. Add a comment documenting: "TRADE-05 finding: committees [ARE/ARE NOT] present in trade detail RSC payloads. [Reason/alternative source]."

7. `test_extract_trade_detail_labels_availability` -- Same pattern as committees. Document TRADE-06 finding.

8. `test_extract_trade_detail_nonexistent_id` -- Call with a trade_id that does not appear in the fixture payload. Verify all fields are None/default (graceful degradation, no panic).

For any field that the fixtures reveal is NOT available in the RSC payload, adjust the test assertion to expect None/empty and add a documenting comment explaining why and where the data should come from instead.

Each test should include a brief comment explaining what requirement it covers (TRADE-01 through TRADE-06).
  </action>
  <verify>
`cargo test -p capitoltraders_lib extract_trade_detail` -- all new tests pass. `cargo test --workspace` -- full suite passes. `cargo clippy --workspace` -- no warnings.
  </verify>
  <done>
8+ fixture-based tests cover all TRADE-01 through TRADE-06 requirements. Tests document actual data availability findings for committees (TRADE-05) and labels (TRADE-06). No regressions in existing tests.
  </done>
</task>

</tasks>

<verification>
1. `cargo test --workspace` passes with 0 failures
2. `cargo clippy --workspace` has no warnings
3. `cargo test -p capitoltraders_lib extract_trade_detail` shows all new tests passing
4. Fixture files exist: `ls capitoltraders_lib/tests/fixtures/trade_detail_*.html` returns 3 files
5. ScrapedTradeDetail has fields: asset_type, size, size_range_high, size_range_low, price, has_capital_gains, committees, labels
</verification>

<success_criteria>
- extract_trade_detail() returns populated asset_type, size fields, price, and filing data from real fixtures
- TRADE-05 (committees) and TRADE-06 (labels) findings are documented in test comments
- All 209+ existing tests continue to pass (no regressions)
- 8+ new fixture-based tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/02-trade-extraction/02-01-SUMMARY.md`
</output>
